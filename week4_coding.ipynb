{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "512c95f6",
   "metadata": {},
   "source": [
    "# ECON30076 Industrial Economics \n",
    "## Week 4 - Assessing Market Power\n",
    "\n",
    "Code for the live lecture\n",
    "\n",
    "This code first simulates choice data given some parameters and then \n",
    "estimates the demand parameters in a Logit model.\n",
    "\n",
    "Outline of the code:\n",
    "\n",
    "0. Settings for the code\n",
    "1. Simulate choice data\n",
    "2. Estimate Logit model to recover demand parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65d2fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, import the required packages\n",
    "# Pandas to work with DataFrames\n",
    "import pandas as pd\n",
    "# Numpy for random draws\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d9a2ac",
   "metadata": {},
   "source": [
    "### 0. Settings\n",
    "\n",
    "We assume consumers choose one out of three PCs. Let us say consumers only\n",
    "care about the price and the number of processing cores.\n",
    "\n",
    "Consumers choose according to indirect utility\n",
    "\n",
    "u = beta_p * price + beta_cores * cores + epsilon\n",
    "\n",
    "where epsilon follows an Extreme value type I distribution.\n",
    "\n",
    "For the simulation, we need to set values for beta_p and beta_cores\n",
    "and we will then draw from the Extreme value type I distribution to simulate\n",
    "choices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ce97e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set values for the utility coefficients\n",
    "beta_p = -10\n",
    "beta_cores = 10\n",
    "\n",
    "### Setting a seed allows you to reproduce results involving random numbers\n",
    "# remove this to obtain different results every time you run it\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e022a05",
   "metadata": {},
   "source": [
    "### 1. Simulate data\n",
    "\n",
    "Steps:\n",
    "1. Create empty data set for 50 consumers choosing from 3 goods\n",
    "    you can change these numbers if you like\n",
    "2. Create observable data (price, cores) for three products\n",
    "3. Calculate mean utility for each observation\n",
    "4. Draw from Extreme value distribution for each observation\n",
    "5. Indicate choice for each consumer that maximises indirect utility\n",
    "\n",
    "Note: When writing a demand estimation code, it is generally good practice to \n",
    "simulate data and try to recover your parameters. This is a good way to check \n",
    "your estimation code works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80c3a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create empty data set for 50 consumers choosing from 3 goods\n",
    "#     you can change these numbers if you like\n",
    "n_cons = 50\n",
    "n_prods = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "339caadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 1.1 Create basic data set structure\n",
    "\n",
    "### We need two identifiers: one for the products, one for the consumers\n",
    "# 50 consumers, each considers all three products\n",
    "\n",
    "# Create a vector of consumer identifiers\n",
    "id_cons = [x for x in range(n_cons)]\n",
    "\n",
    "## Loop through products and create a DataFrame with these consumer IDs and \n",
    "# the respective product ID. Add everything into a list\n",
    "# Empty list to save in\n",
    "dflist = []\n",
    "for i in range(n_prods):\n",
    "    df_sub = pd.DataFrame(id_cons, columns = ['consumer_id'])\n",
    "    # Add column with product ID\n",
    "    df_sub['product_id'] = i\n",
    "    # Add to list\n",
    "    dflist.append(df_sub)\n",
    "    \n",
    "## Combine dflist to one DataFrame\n",
    "df = pd.concat(dflist)\n",
    "# Sort by consumer_id first\n",
    "df.sort_values(['consumer_id', 'product_id'], inplace = True)\n",
    "# Reset index\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "980bc97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 1.2 Create product characteristics\n",
    "# Draw prices and cores from uniform distribution between 0 and 1\n",
    "df['price'] = np.random.uniform(size = len(df))\n",
    "df['cores'] = np.random.uniform(size = len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bfb43d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 1.3 Calculate mean utility\n",
    "# Given the observable product characteristics and the beta coefficients from\n",
    "# above, we can calculate the mean utility (denoted as delta in the slides)\n",
    "df['delta'] = beta_p * df['price'] + beta_cores * df['cores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0b3aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 1.4 Draw error terms\n",
    "### We draw the unobserved utility component from an Extreme value distribution \n",
    "# The standard Extreme value distribution is also called Standard Gumbel distribution\n",
    "\n",
    "# Draw Standard Gumbel distribution using numpy\n",
    "df['errors'] = np.random.gumbel(size = len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da60a461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('product_id', 'chosen')",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "23e3d494-2854-48da-b333-e3bc7cd881a0",
       "rows": [
        [
         "(0, 0)",
         "28"
        ],
        [
         "(0, 1)",
         "22"
        ],
        [
         "(1, 0)",
         "40"
        ],
        [
         "(1, 1)",
         "10"
        ],
        [
         "(2, 0)",
         "32"
        ],
        [
         "(2, 1)",
         "18"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 6
       }
      },
      "text/plain": [
       "product_id  chosen\n",
       "0           0         28\n",
       "            1         22\n",
       "1           0         40\n",
       "            1         10\n",
       "2           0         32\n",
       "            1         18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### 1.5 Simulate choices\n",
    "### Calculate indirect utility as delta + errors\n",
    "df['utility'] = df['delta'] + df['errors']\n",
    "\n",
    "### For each consumer, take maximum utility value\n",
    "df_max = df[['consumer_id', 'utility']].groupby('consumer_id').agg('max') \\\n",
    "    .reset_index().rename(columns = {'utility': 'maxU'})\n",
    "# Merge back\n",
    "df = df.merge(df_max, on = 'consumer_id', how = 'left', validate = 'm:1')\n",
    "# Indicator for chosen product\n",
    "df['chosen'] = (df['utility'] == df['maxU']).astype(int)\n",
    "\n",
    "### Look at choices\n",
    "df.groupby(['product_id', 'chosen']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44948a98",
   "metadata": {},
   "source": [
    "### 2. Estimate logit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9251e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before estimating, let us 'forget' everything that would be normally unobserved.\n",
    "df.drop(columns = ['delta', 'errors', 'utility', 'maxU'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87255b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "beta_p = 0, beta_cores = 0\n",
      "Total log-likelihood: -54.93061443340549\n"
     ]
    }
   ],
   "source": [
    "###### 2.1 Estimation by hand\n",
    "\n",
    "#### Start by assuming some value for beta_p and beta_cores\n",
    "beta_p_ml = 0\n",
    "beta_cores_ml = 0\n",
    "# Use these to calculate log likelihood\n",
    "\n",
    "### Recall: Individual likelihoods are given by logit choice probability\n",
    "# prob = exp(delta)/sum of exp(delta) over all choices\n",
    "# delta = beta_p_ml * price + beta_cores_ml * cores\n",
    "\n",
    "# Delta\n",
    "df['delta'] = beta_p_ml * df['price'] + beta_cores_ml * df['cores']\n",
    "# Calculate exp(delta)\n",
    "df['exp_d'] = np.exp(df['delta'])\n",
    "# Calculate sum of exps of delta for each consumer\n",
    "df_cons = df[['consumer_id', 'exp_d']].groupby('consumer_id').agg('sum') \\\n",
    "    .reset_index().rename(columns = {'exp_d': 'sum_exp'})\n",
    "df = df.merge(df_cons, on = 'consumer_id', how = 'left', validate = 'm:1')\n",
    "# Calculate logit choice probability\n",
    "df['probs'] = df['exp_d'] / df['sum_exp']\n",
    "# Take log likelihood\n",
    "df['ll'] = np.log(df['probs'])\n",
    "\n",
    "### For the total log likelihood, we want to sum individual likelihoods, but only\n",
    "# for the chosen alternatives\n",
    "df['ll_chosen'] = df['ll'] * df['chosen']\n",
    "# Sum and display total log likelihood\n",
    "ll = df['ll_chosen'].sum()\n",
    "print('\\nbeta_p = %s, beta_cores = %s\\nTotal log-likelihood: %s' \\\n",
    "    % (beta_p_ml, beta_cores_ml, ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43bf64c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "beta_p = -10, beta_cores = 10\n",
      "Total log-likelihood: -15.369275992416942\n"
     ]
    }
   ],
   "source": [
    "#### Let us try again, this time with the true parameter values\n",
    "beta_p_ml = beta_p\n",
    "beta_cores_ml = beta_cores\n",
    "# Drop previously created variables\n",
    "df.drop(columns = ['delta', 'exp_d', 'sum_exp', 'probs', 'll'], inplace = True)\n",
    "\n",
    "# Delta\n",
    "df['delta'] = beta_p_ml * df['price'] + beta_cores_ml * df['cores']\n",
    "# Calculate exp(delta)\n",
    "df['exp_d'] = np.exp(df['delta'])\n",
    "# Calculate sum of exps of delta for each consumer\n",
    "df_cons = df[['consumer_id', 'exp_d']].groupby('consumer_id').agg('sum') \\\n",
    "    .reset_index().rename(columns = {'exp_d': 'sum_exp'})\n",
    "df = df.merge(df_cons, on = 'consumer_id', how = 'left', validate = 'm:1')\n",
    "# Calculate logit choice probability\n",
    "df['probs'] = df['exp_d'] / df['sum_exp']\n",
    "# Take log likelihood\n",
    "df['ll'] = np.log(df['probs'])\n",
    "\n",
    "### For the total log likelihood, we want to sum individual likelihoods, but only\n",
    "# for the chosen alternatives\n",
    "df['ll_chosen'] = df['ll'] * df['chosen']\n",
    "# Sum and display total log likelihood\n",
    "ll = df['ll_chosen'].sum()\n",
    "print('\\nbeta_p = %s, beta_cores = %s\\nTotal log-likelihood: %s' \\\n",
    "    % (beta_p_ml, beta_cores_ml, ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0330099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "beta_p = -1, beta_cores = 1\n",
      "Total log-likelihood: -41.82032982257603\n"
     ]
    }
   ],
   "source": [
    "#### Let us try again, this time with some other parameter values\n",
    "beta_p_ml = -1\n",
    "beta_cores_ml = 1\n",
    "# Drop previously created variables\n",
    "df.drop(columns = ['delta', 'exp_d', 'sum_exp', 'probs', 'll'], inplace = True)\n",
    "\n",
    "# Delta\n",
    "df['delta'] = beta_p_ml * df['price'] + beta_cores_ml * df['cores']\n",
    "# Calculate exp(delta)\n",
    "df['exp_d'] = np.exp(df['delta'])\n",
    "# Calculate sum of exps of delta for each consumer\n",
    "df_cons = df[['consumer_id', 'exp_d']].groupby('consumer_id').agg('sum') \\\n",
    "    .reset_index().rename(columns = {'exp_d': 'sum_exp'})\n",
    "df = df.merge(df_cons, on = 'consumer_id', how = 'left', validate = 'm:1')\n",
    "# Calculate logit choice probability\n",
    "df['probs'] = df['exp_d'] / df['sum_exp']\n",
    "# Take log likelihood\n",
    "df['ll'] = np.log(df['probs'])\n",
    "\n",
    "### For the total log likelihood, we want to sum individual likelihoods, but only\n",
    "# for the chosen alternatives\n",
    "df['ll_chosen'] = df['ll'] * df['chosen']\n",
    "# Sum and display total log likelihood\n",
    "ll = df['ll_chosen'].sum()\n",
    "print('\\nbeta_p = %s, beta_cores = %s\\nTotal log-likelihood: %s' \\\n",
    "    % (beta_p_ml, beta_cores_ml, ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67481a7c",
   "metadata": {},
   "source": [
    "Now, we would need a way to loop over various combinations of parameter\n",
    "values to find the ones that maximise the log-likelihood\n",
    "Luckily, people have implemented packages that automate this for us already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "228592bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood at zero: -54.9306\n",
      "Initial Log-likelihood: -54.9306\n",
      "Estimation Time for Point Estimation: 0.00 seconds.\n",
      "Final log-likelihood: -15.0864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ugio/lib/python3.9/site-packages/pylogit/estimation.py:678: RuntimeWarning: Method BFGS does not use Hessian information (hess).\n",
      "  results = minimize(estimator.calc_neg_log_likelihood_and_neg_gradient,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Multinomial Logit Model Regression Results                    \n",
      "===================================================================================\n",
      "Dep. Variable:                      chosen   No. Observations:                   50\n",
      "Model:             Multinomial Logit Model   Df Residuals:                       48\n",
      "Method:                                MLE   Df Model:                            2\n",
      "Date:                     Tue, 10 Feb 2026   Pseudo R-squ.:                   0.725\n",
      "Time:                             13:10:55   Pseudo R-bar-squ.:               0.689\n",
      "AIC:                                34.173   Log-Likelihood:                -15.086\n",
      "BIC:                                37.997   LL-Null:                       -54.931\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "price        -10.5906      2.656     -3.987      0.000     -15.796      -5.385\n",
      "cores         11.7723      3.303      3.565      0.000       5.299      18.245\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#%% 2.2 Estimation using pylogit package\n",
    "import pylogit\n",
    "from collections import OrderedDict\n",
    "\n",
    "### Prepare specification\n",
    "basic_specification = OrderedDict()\n",
    "basic_names = OrderedDict()\n",
    "\n",
    "for var in ['price', 'cores']:\n",
    "    \n",
    "    # Add variable to ordered dict\n",
    "    basic_specification[var] = [list(set(df[\"product_id\"]))]\n",
    "    basic_names[var] = [var]\n",
    "    \n",
    "### Create the multinomial logit model (MNL) estimator\n",
    "est_mnl = pylogit.create_choice_model(data = df,\n",
    "    alt_id_col = \"product_id\",\n",
    "    obs_id_col = \"consumer_id\",\n",
    "    choice_col = \"chosen\",\n",
    "    specification = basic_specification,\n",
    "    model_type = \"MNL\",\n",
    "    names = basic_names)\n",
    "\n",
    "# Specify the initial values and method for the optimization and estimate\n",
    "est_mnl.fit_mle(np.zeros(len(basic_specification)))\n",
    "\n",
    "# Look at the estimation results\n",
    "print(est_mnl.get_statsmodels_summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ugio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
